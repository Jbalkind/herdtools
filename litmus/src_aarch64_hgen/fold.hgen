| `AArch64AddSubCarry (d,n,m,sf,sub_op,setflags) -> fold_reg m (fold_reg n (fold_reg d (y_reg, y_sreg)))
| `AArch64AddSubExtendRegister (d,n,m,sf,sub_op,setflags,extend_type,shift) -> fold_reg m (fold_reg n (fold_reg d (y_reg, y_sreg)))
| `AArch64AddSubShiftedRegister (d,n,m,sf,sub_op,setflags,shift_type,shift_amount) -> fold_reg m (fold_reg n (fold_reg d (y_reg, y_sreg)))
| `AArch64AddSubImmediate (d,n,sf,sub_op,setflags,imm) -> fold_reg n (fold_reg d (y_reg, y_sreg))
| `AArch64Address (d,sf,page,imm) -> fold_reg d (y_reg, y_sreg)
| `AArch64LogicalImmediate (d,n,sf,setflags,op,imm) -> fold_reg n (fold_reg d (y_reg, y_sreg))
| `AArch64LogicalShiftedRegister (d,n,m,sf,setflags,op,shift_type,shift_amount,invert) -> fold_reg m (fold_reg n (fold_reg d (y_reg, y_sreg)))
| `AArch64Shift (d,n,m,sf,shift_type) -> fold_reg m (fold_reg n (fold_reg d (y_reg, y_sreg)))
| `AArch64BranchConditional (offset,condition) -> (y_reg, y_sreg)
| `AArch64BranchImmediate (_branch_type,offset) -> (y_reg, y_sreg)
| `AArch64BitfieldMove (d,n,sf,inzero,extend,_R,_S,wmask,tmask) -> fold_reg n (fold_reg d (y_reg, y_sreg))
| `AArch64BranchRegister (n,_branch_type) -> fold_reg n (y_reg, y_sreg)
| `AArch64CompareAndBranch (t,sf,iszero,offset) -> fold_reg t (y_reg, y_sreg)
| `AArch64ConditionalCompareImmediate (n,sf,sub_op,condition,flags,imm) -> fold_reg n (y_reg, y_sreg)
| `AArch64ConditionalCompareRegister (n,m,sf,sub_op,condition,flags) -> fold_reg m (fold_reg n (y_reg, y_sreg))
| `AArch64ClearExclusiveMonitor (imm) -> (y_reg, y_sreg)
| `AArch64CountLeading (d,n,sf,opcode) -> fold_reg n (fold_reg d (y_reg, y_sreg))
| `AArch64CRC (d,n,m,sf,size,crc32c) -> fold_reg m (fold_reg n (fold_reg d (y_reg, y_sreg)))
| `AArch64ConditionalSelect (d,n,m,sf,condition,else_inv,else_inc) -> fold_reg m (fold_reg n (fold_reg d (y_reg, y_sreg)))
| `AArch64Barrier (op,domain,types) -> (y_reg, y_sreg)
| `AArch64ExtractRegister (d,n,m,sf,lsb) -> fold_reg m (fold_reg n (fold_reg d (y_reg, y_sreg)))
| `AArch64Hint (op) -> (y_reg, y_sreg)
| `AArch64LoadStoreAcqExc (n,t,t2,s,acctype,excl,pair,memop,elsize,sf,df,datasize) -> fold_reg s (fold_reg t2 (fold_reg t (fold_reg n (y_reg, y_sreg))))
| `AArch64LoadStorePair (wback,postindex,n,t,t2,acctype,memop,signed,scale,sf,df,datasize,offset) -> fold_reg t2 (fold_reg t (fold_reg n (y_reg, y_sreg)))
| `AArch64LoadImediate (n,t,acctype,memop,signed,wback,postindex,offset,sf,df,datasize) -> fold_reg t (fold_reg n (y_reg, y_sreg))
| `AArch64LoadLiteral (t,memop,signed,sf,df,size,offset) -> fold_reg t (y_reg, y_sreg)
| `AArch64LoadRegister (n,t,m,acctype,memop,signed,wback,postindex,extend_type,shift,sf,df,datasize) -> fold_reg m (fold_reg t (fold_reg n (y_reg, y_sreg)))
| `AArch64MultiplyAddSub (d,n,m,a,sf,sub_op) -> fold_reg a (fold_reg m (fold_reg n (fold_reg d (y_reg, y_sreg))))
| `AArch64MoveWide (d,sf,imm,pos,opcode) -> fold_reg d (y_reg, y_sreg)
| `AArch64Reverse (d,n,sf,op) -> fold_reg n (fold_reg d (y_reg, y_sreg))
| `AArch64Division (d,n,m,sf,unsigned) -> fold_reg m (fold_reg n (fold_reg d (y_reg, y_sreg)))
| `AArch64MultiplyAddSubLong (d,n,m,a,destsize,datasize,sub_op,unsigned) -> fold_reg a (fold_reg m (fold_reg n (fold_reg d (y_reg, y_sreg))))
| `AArch64MultiplyHigh (d,n,m,a,sf,destsize,datasize,unsigned) -> fold_reg a (fold_reg m (fold_reg n (fold_reg d (y_reg, y_sreg))))
| `AArch64TestBitAndBranch (t,sf,bit_pos,bit_val,offset) -> fold_reg t (y_reg, y_sreg)
